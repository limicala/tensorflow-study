{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存&恢复模型\n",
    "设置一个值为1000\n",
    "\n",
    "如果经过1000次迭代，这1000次迭代准确率没有提高，则停止优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Use PrettyTensor to simplify Neural Network construction.\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "data.validation.cls = np.argmax(data.validation.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.validation.cls[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        \n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "        \n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "            \n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "\n",
    "x_image = tf.reshape(x, shape=[-1, img_size, img_size, num_channels])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\n",
    "\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        conv2d(kernel=5, depth=16, name='layer_conv1').\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        conv2d(kernel=5, depth=36, name='layer_conv2').\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        flatten().\\\n",
    "        fully_connected(size=128, name='layer_fc1').\\\n",
    "        softmax_classifier(num_classes=num_classes, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights_variable(layer_name):\n",
    "    # Retrieve an existing variable named 'weights' in the scope\n",
    "    # with the given layer_name.\n",
    "    # This is awkward because the TensorFlow function was\n",
    "    # really intended for another purpose.\n",
    "\n",
    "    with tf.variable_scope(layer_name, reuse=True):\n",
    "        variable = tf.get_variable('weights')\n",
    "\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "def predict_cls(images, labels, cls_true):\n",
    "    \n",
    "    num_images = len(images)\n",
    "    \n",
    "    cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "    \n",
    "    i = 0\n",
    "    while i < num_images:\n",
    "        \n",
    "        j = min(i + batch_size, num_images)\n",
    "        \n",
    "        feed_dict = {x: images[i:j, :],\n",
    "                     y_true: labels[i:j, :]}\n",
    "        \n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        \n",
    "        i = j\n",
    "    \n",
    "    correct = (cls_true == cls_pred)\n",
    "    \n",
    "    return correct, cls_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cls_test():\n",
    "    return predict_cls(images = data.test.images,\n",
    "                       labels = data.test.labels,\n",
    "                       cls_true = data.test.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_cls_validation():\n",
    "    return predict_cls(images = data.validation.images,\n",
    "                       labels = data.validation.labels,\n",
    "                       cls_true = data.validation.cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# eg: correct = [True, False, True, True]\n",
    "def cls_accuray(correct):\n",
    "    \n",
    "    correct_sum = correct.sum()\n",
    "    \n",
    "    acc = float(correct_sum) / len(correct)\n",
    "    \n",
    "    return acc, correct_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_accuracy():\n",
    "    \n",
    "    correct, _ = predict_cls_validation()\n",
    "    \n",
    "    return cls_accuray(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints/'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(save_dir, 'best_validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_variables():\n",
    "    session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "\n",
    "best_validation_accuracy = 0.0\n",
    "\n",
    "last_improvement = 0\n",
    "\n",
    "require_improvement = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_iterations = 0\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    \n",
    "    global total_iterations\n",
    "    global best_validation_accuracy\n",
    "    global last_improvement\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        total_iterations += 1\n",
    "        \n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "        \n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        \n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        # log every 100 or the last one\n",
    "        if (total_iterations % 100 == 0) or (i == (num_iterations - 1)):\n",
    "            \n",
    "            # training-batch accuracy\n",
    "            acc_train = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # validation-batch accuracy\n",
    "            # 另外计算校验集的准确率\n",
    "            acc_validation, _ = validation_accuracy()\n",
    "            \n",
    "            if acc_validation > best_validation_accuracy:\n",
    "                \n",
    "                best_validation_accuracy = acc_validation\n",
    "                \n",
    "                # 当前迭代次数\n",
    "                last_improvement = total_iterations\n",
    "                \n",
    "                # 保存模型到文件里\n",
    "                saver.save(sess=session, save_path=save_path)\n",
    "                \n",
    "                improved_str = '*'\n",
    "            else:\n",
    "                \n",
    "                improved_str = ''\n",
    "            # Status-message for printing.\n",
    "            msg = \"Iter: {0:>6}, Train-Batch Accuracy: {1:>6.1%}, Validation Acc: {2:>6.1%} {3}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc_train, acc_validation, improved_str))\n",
    "        \n",
    "        # If no improvement found in the required number of iterations.\n",
    "        # 无法再优化了\n",
    "        if total_iterations - last_improvement > require_improvement:\n",
    "            print(\"No improvement found in a while, stopping optimization.\")\n",
    "\n",
    "            # Break out from the for-loop.\n",
    "            break\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    time_diff = end_time - start_time\n",
    "    \n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_diff)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_test_accuracy():\n",
    "    \n",
    "    correct, cls_pred = predict_cls_test()\n",
    "    \n",
    "    acc, num_correct = cls_accuray(correct)\n",
    "    \n",
    "    num_images = len(correct)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, num_correct, num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 10.8% (1084 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    100, Train-Batch Accuracy:  92.2%, Validation Acc:  92.9% *\n",
      "Time usage: 0:00:15\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 10.6% (1056 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次初始化之后，准确率变低了，变成迭代之前的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/best_validation\n"
     ]
    }
   ],
   "source": [
    "# 恢复之前保存的变量\n",
    "saver.restore(sess=session, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 93.1% (9309 / 10000)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()\n",
    "# 准确率恢复为90%以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
