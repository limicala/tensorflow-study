{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成学习\n",
    "\n",
    "> 《机器学习实战》第7章\n",
    "\n",
    "> 当做重要决定时，会考虑多个专家而不是一个人的意见，这就是**元算法**背后的思路。元算法是对其他算法进行组合的一种方式。\n",
    "\n",
    "集成学习是用多个分类器来通过同一个数据集来训练，每个分类器的结果再设置权值\n",
    "\n",
    "步骤：\n",
    "把数据集随机重组成n个数据集，交给n个分类器去处理，最后把每个分类器的输出乘上该分类器所对应的权值，求和作为最后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Use PrettyTensor to simplify Neural Network construction.\n",
    "import prettytensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# axis 默认情况下，索引的是平铺的数组，否则沿指定的轴。 \n",
    "# 比如axis=1则表示每一y轴上的点\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "data.validation.cls = np.argmax(data.validation.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_images = np.concatenate([data.train.images, data.validation.images], axis=0)\n",
    "combined_labels = np.concatenate([data.train.labels, data.validation.labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 组合的数据集大小\n",
    "combined_size = len(combined_images)\n",
    "combined_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80%作为训练集\n",
    "train_size = int(0.8 * combined_size)\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用于校验\n",
    "validation_size = combined_size - train_size\n",
    "validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 随机生成训练集\n",
    "def random_training_set():\n",
    "    \n",
    "    idx = np.random.permutation(combined_size)\n",
    "    \n",
    "    idx_train = idx[0:train_size]\n",
    "    idx_validation = idx[train_size:]\n",
    "    \n",
    "    x_train = combined_images[idx_train, :]\n",
    "    y_train = combined_labels[idx_train, :]\n",
    "    \n",
    "#     x_validation = combined_images[train_size, :]\n",
    "    x_validation = combined_images[train_size]\n",
    "    y_validation = combined_labels[train_size]\n",
    "    \n",
    "    return x_train, y_train, x_validation, y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We know that MNIST images are 28 pixels in each dimension.\n",
    "img_size = 28\n",
    "\n",
    "# Images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = img_size * img_size\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 1\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画图函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images,                  # Images to plot, 2-d array.\n",
    "                cls_true,                # True class-no for images.\n",
    "                ensemble_cls_pred=None,  # Ensemble predicted class-no.\n",
    "                best_cls_pred=None):     # Best-net predicted class-no.\n",
    "\n",
    "    assert len(images) == len(cls_true)\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    # Adjust vertical spacing if we need to print ensemble and best-net.\n",
    "    if ensemble_cls_pred is None:\n",
    "        hspace = 0.3\n",
    "    else:\n",
    "        hspace = 1.0\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=0.3)\n",
    "\n",
    "    # For each of the sub-plots.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        # There may not be enough images for all sub-plots.\n",
    "        if i < len(images):\n",
    "            # Plot image.\n",
    "            ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "            # Show true and predicted classes.\n",
    "            if ensemble_cls_pred is None:\n",
    "                xlabel = \"True: {0}\".format(cls_true[i])\n",
    "            else:\n",
    "                msg = \"True: {0}\\nEnsemble: {1}\\nBest Net: {2}\"\n",
    "                xlabel = msg.format(cls_true[i],\n",
    "                                    ensemble_cls_pred[i],\n",
    "                                    best_cls_pred[i])\n",
    "\n",
    "            # Show the classes as the label on the x-axis.\n",
    "            ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义输入和输出的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用PrettyTensor构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pretty = pt.wrap(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_pred, loss = x_pretty.\\\n",
    "        conv2d(kernel=5, depth=16, name='layer_conv1').\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        conv2d(kernel=5, depth=36, name='layer_conv2').\\\n",
    "        max_pool(kernel=2, stride=2).\\\n",
    "        flatten().\\\n",
    "        fully_connected(size=128, name='layer_fc1').\\\n",
    "        softmax_classifier(num_classes=num_classes, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 优化器\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saver\n",
    "\n",
    "把多个神经网络保存到文件里面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=100) # 最多保存100个神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_save_path(net_number):\n",
    "    return save_dir + 'network' + str(net_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_variables():\n",
    "    session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 不同于之前的按顺序取出batch来训练，这里还要随机取batch\n",
    "def random_batch(x_train, y_train):\n",
    "    \n",
    "    num_images = len(x_train)\n",
    "    \n",
    "    # 在[0, num_images) 生成train_batch_size 个随机数\n",
    "    idx = np.random.choice(num_images,\n",
    "                           size=train_batch_size,\n",
    "                           replace=False)\n",
    "    \n",
    "    x_batch = x_train[idx, :]\n",
    "    y_batch = y_train[idx, :]\n",
    "    \n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(num_iterations, x_train, y_train):\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = random_batch(x_train, y_train)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations and after last iteration.\n",
    "        if i % 100 == 0:\n",
    "\n",
    "            # Calculate the accuracy on the training-batch.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            \n",
    "            # Status-message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_networks = 5\n",
    "num_iterations = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network: 0\n",
      "Optimization Iteration:      1, Training Batch Accuracy:  10.9%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    501, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  96.9%\n",
      "Time usage: 0:01:55\n",
      "\n",
      "Neural network: 1\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   6.2%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  85.9%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  96.9%\n",
      "Time usage: 0:01:56\n",
      "\n",
      "Neural network: 2\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   4.7%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  82.8%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  92.2%\n",
      "Time usage: 0:01:52\n",
      "\n",
      "Neural network: 3\n",
      "Optimization Iteration:      1, Training Batch Accuracy:  12.5%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  89.1%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  84.4%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  90.6%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  98.4%\n",
      "Optimization Iteration:    601, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  96.9%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  95.3%\n",
      "Time usage: 0:01:55\n",
      "\n",
      "Neural network: 4\n",
      "Optimization Iteration:      1, Training Batch Accuracy:   3.1%\n",
      "Optimization Iteration:    101, Training Batch Accuracy:  82.8%\n",
      "Optimization Iteration:    201, Training Batch Accuracy:  84.4%\n",
      "Optimization Iteration:    301, Training Batch Accuracy:  92.2%\n",
      "Optimization Iteration:    401, Training Batch Accuracy:  93.8%\n",
      "Optimization Iteration:    501, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    601, Training Batch Accuracy: 100.0%\n",
      "Optimization Iteration:    701, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    801, Training Batch Accuracy:  95.3%\n",
      "Optimization Iteration:    901, Training Batch Accuracy:  95.3%\n",
      "Time usage: 0:01:53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    \n",
    "    for i in range(num_networks):\n",
    "        print(\"Neural network: {0}\".format(i))\n",
    "        \n",
    "        x_train, y_train, _, _ = random_training_set()\n",
    "        \n",
    "        session.run(tf.global_variables_initializer())\n",
    "        \n",
    "        optimize(num_iterations=num_iterations,\n",
    "                 x_train=x_train,\n",
    "                 y_train=y_train)\n",
    "        \n",
    "        saver.save(sess=session, save_path=get_save_path(i))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble\n",
    "集成学习会根据一张图片的输入得到的五个分类器的输出，对同一类别的标签（一共有10类）去平均值，找出最大值的下标，作为该图片的最终输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 代码待写"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
